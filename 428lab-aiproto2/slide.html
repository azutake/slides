<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLMトークナイザー性能改善研究 (Polished) - 15min Talk</title>
    <style>
        :root {
            --primary-color: #2563eb;
            --secondary-color: #1e40af;
            --accent-color: #f59e0b;
            --text-color: #334155;
            --bg-color: #ffffff;
            --slide-bg: #f8fafc;
            --code-bg: #1e293b;
            --code-text: #e2e8f0;
            --note-bg: #fff1f2;
            --note-text: #881337;
        }

        body {
            margin: 0;
            padding: 0;
            font-family: 'Helvetica Neue', Arial, 'Hiragino Kaku Gothic ProN', 'Hiragino Sans', sans-serif;
            background-color: #0f172a;
            color: var(--text-color);
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }

        #presentation {
            width: 100%;
            height: 100%;
            position: relative;
            background-color: #cbd5e1;
        }

        .slide {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: var(--slide-bg);
            /* レイアウト修正: GridからFlexに変更してh3の伸長を防止 */
            display: flex;
            flex-direction: column;
            padding: 3rem 5rem;
            box-sizing: border-box;
            opacity: 0;
            transform: translateY(20px);
            transition: all 0.4s ease-in-out;
            visibility: hidden;
            overflow-y: auto;
        }

        .slide.active {
            opacity: 1;
            transform: translateY(0);
            visibility: visible;
            z-index: 10;
        }

        /* Typography */
        h1 {
            font-size: 3.2rem;
            color: var(--primary-color);
            margin: 0;
            line-height: 1.1;
        }
        
        .slide-header {
            border-bottom: 3px solid #e2e8f0;
            padding-bottom: 1rem;
            margin-bottom: 2rem;
            display: flex;
            justify-content: space-between;
            align-items: end;
            flex-shrink: 0; /* ヘッダーが潰れないように */
        }

        .slide-header h2 {
            font-size: 2.2rem;
            color: var(--secondary-color);
            margin: 0;
        }

        .slide-header .page-num {
            font-size: 1.2rem;
            color: #94a3b8;
        }

        h3 {
            font-size: 1.6rem;
            color: var(--primary-color);
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
            border-left: 5px solid var(--accent-color);
            padding-left: 1rem;
            /* Flexアイテムとしての挙動を制御 */
            align-self: flex-start;
            width: 100%; 
        }

        p, li {
            font-size: 1.4rem;
            line-height: 1.6;
            margin-bottom: 0.8rem;
            color: var(--text-color);
        }

        ul { padding-left: 1.5rem; }

        strong {
            color: var(--secondary-color);
            font-weight: 700;
        }

        .highlight {
            background: rgba(245, 158, 11, 0.2);
            padding: 0 0.2em;
            border-radius: 4px;
        }

        .quote-box {
            background-color: #f1f5f9;
            border-left: 5px solid #64748b;
            padding: 1.5rem;
            margin: 1.5rem 0;
            font-style: italic;
            color: #475569;
            position: relative;
        }
        
        .quote-box::before {
            content: "“";
            font-size: 4rem;
            color: #cbd5e1;
            position: absolute;
            top: -10px;
            left: 10px;
        }

        .source {
            text-align: right;
            font-size: 1rem;
            color: #64748b;
            margin-top: 0.5rem;
        }

        /* Diagrams */
        .cif-diagram {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 1rem;
            margin: 2rem 0;
            background: white;
            padding: 2rem;
            border-radius: 12px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        }
        
        .cif-step {
            display: flex;
            flex-direction: column;
            align-items: center;
            width: 120px;
        }
        
        .cif-bucket {
            width: 60px;
            height: 80px;
            border: 3px solid #334155;
            border-top: none;
            position: relative;
            background: #f1f5f9;
            border-radius: 0 0 8px 8px;
            overflow: hidden;
        }
        
        .water {
            background-color: var(--primary-color);
            position: absolute;
            bottom: 0;
            left: 0;
            width: 100%;
            transition: height 0.5s;
        }
        
        .arrow { font-size: 2rem; color: #94a3b8; }

        .arch-diagram {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            margin: 1rem 0;
            text-align: center;
            font-family: monospace;
            font-size: 1.2rem;
            color: #334155;
            border: 1px solid #e2e8f0;
        }
        
        .clt-pipeline {
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: white;
            padding: 2rem;
            border-radius: 12px;
            margin: 2rem 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        }
        
        .pipeline-box {
            background: #f1f5f9;
            border: 2px solid #cbd5e1;
            padding: 1rem;
            border-radius: 8px;
            text-align: center;
            width: 18%;
        }
        
        .pipeline-box.core {
            border-color: var(--accent-color);
            background: #fffbeb;
        }

        /* Speaker Notes */
        .speaker-notes {
            /* Flex layout変更に伴い、margin-top: autoで下に押し下げる */
            margin-top: auto;
            border-top: 2px dashed #cbd5e1;
            padding-top: 1rem;
            background-color: #fffbeb;
            padding: 1rem;
            border-radius: 8px;
            font-size: 1rem;
            color: #78350f;
            max-height: 15vh;
            overflow-y: auto;
            flex-shrink: 0;
        }
        .speaker-notes strong { color: #d97706; }

        /* Two Col */
        .two-col {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 3rem;
            align-items: start;
        }

        /* Vocab Card */
        .vocab-card {
            background: white;
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            margin-bottom: 1rem;
        }
        .vocab-example {
            font-family: monospace;
            font-size: 1.3rem;
            display: flex;
            justify-content: space-between;
            border-bottom: 1px dotted #ccc;
            padding: 0.5rem 0;
        }

        /* Controls */
        .controls {
            position: fixed;
            bottom: 20px;
            right: 20px;
            display: flex;
            gap: 10px;
            z-index: 100;
        }
        .btn {
            background: rgba(255,255,255,0.9);
            border: 1px solid #cbd5e1;
            padding: 10px 20px;
            border-radius: 6px;
            cursor: pointer;
            font-weight: bold;
            color: var(--text-color);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .btn:hover { background: white; transform: translateY(-1px); }

        .progress-bar {
            position: fixed;
            bottom: 0;
            left: 0;
            height: 5px;
            background: var(--accent-color);
            width: 0%;
            transition: width 0.3s;
            z-index: 200;
        }
        
        .title-slide {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            text-align: center;
            background: linear-gradient(135deg, #eff6ff 0%, #fff 100%);
        }
        .title-slide h1 { font-size: 4rem; margin-bottom: 1rem; }
        
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 1rem;
            font-size: 1.2rem;
        }
        .comparison-table th, .comparison-table td {
            border: 1px solid #cbd5e1;
            padding: 0.8rem;
            text-align: left;
        }
        .comparison-table th {
            background-color: #f1f5f9;
            color: var(--secondary-color);
        }
    </style>
</head>
<body>

<div id="presentation">

    <!-- Slide 1: Title -->
    <div class="slide title-slide active">
        <h1>LLMトークナイザー<br>性能改善研究</h1>
        <p class="subtitle" style="font-size:1.8rem; color:#64748b;">PFNの知見から学ぶ「予測しやすい語彙」と<br>形態素解析フリーへの挑戦</p>
        <div style="margin-top: 3rem;">
            <p><strong>Presenter:</strong> Azutake</p>
            <p><strong>Date:</strong> 2026/01/15</p>
        </div>
        
        <div class="speaker-notes">
            <strong>【導入: 1分】</strong><br>
            ・本日はトークナイザーの研究について話します。<br>
            ・LLMの性能はモデルサイズだけでなく、「どう言葉を区切るか」に大きく依存します。<br>
            ・PFNの事例、Meta BLTの課題、そして独自の解決策(CLT)について詳説します。
        </div>
    </div>

    <!-- Slide 2: Context (BPE Issues) -->
    <div class="slide">
        <div class="slide-header">
            <h2>1. 背景：BPEトークナイザーの課題</h2>
            <span class="page-num">01 / 14</span>
        </div>
        
        <h3>ChatGPTやGeminiの現状</h3>
        <p>主流のBPE (Byte Pair Encoding) は、データ量に依存して結合ルールを学習する。</p>
        
        <div class="two-col" style="margin-top:2rem;">
            <div class="vocab-card">
                <h4 style="margin:0 0 1rem 0; color:#ef4444;">英語 (High Resource)</h4>
                <p>データが豊富で、適切な単語単位でトークン化されやすい。</p>
                <div class="vocab-example">
                    <span>Example</span> → <span>[Example] (1 token)</span>
                </div>
            </div>
            <div class="vocab-card">
                <h4 style="margin:0 0 1rem 0; color:#2563eb;">日本語 (Low Resource)</h4>
                <p>相対的にデータが少なく、結合が進まない。</p>
                <div class="vocab-example">
                    <span>例えば</span> → <span>[例][え][ば] (3 tokens)</span>
                </div>
                <p class="highlight">→ 1文字1トークンになりがち。</p>
            </div>
        </div>

        <p style="margin-top: 1rem;">
            <strong>問題点:</strong> 日本語は同じ情報を表現するのに必要なトークン数が多く、<br>
            推論速度（レスポンス）が遅くなり、コンテキストウィンドウも圧迫する。
        </p>

        <div class="speaker-notes">
            <strong>【BPEの課題: 2分】</strong><br>
            ・一般的に使われているBPEですが、日本語には不利な側面があります。<br>
            ・英語は1単語1トークンで綺麗に収まりますが、日本語はデータ量の差で細切れになりがちです。<br>
            ・これはAPIコストや生成速度に直結する重要な問題です。
        </div>
    </div>

    <!-- Slide 3: Context (Token Efficiency) -->
    <div class="slide">
        <div class="slide-header">
            <h2>2. 効率と性能のトレードオフ</h2>
            <span class="page-num">02 / 14</span>
        </div>
        
        <h3>「トークン効率を上げれば良い」のか？</h3>
        <ul>
            <li><strong>メリット:</strong> 1トークンに多くの文字を圧縮できれば、レスポンスは高速化する。</li>
            <li><strong>デメリット (Over-compression):</strong> <br>
                闇雲に圧縮すると、似た意味の言葉が全く別のID（ベクトル）になってしまう。</li>
        </ul>

        <div class="vocab-card" style="margin-top:2rem; background:#fef2f2;">
            <h4>⚠️ 失敗例：過度な圧縮</h4>
            <div class="vocab-example">
                <span>[美味しい]</span> vs <span>[美味い]</span>
            </div>
            <p>これらを別々の巨大な1トークンとして登録してしまうと、<br>
            共通の「美味」という概念をモデルが捉えにくくなり、<strong>汎化性能が低下</strong>する。</p>
        </div>

        <div class="speaker-notes">
            <strong>【圧縮のジレンマ: 2分】</strong><br>
            ・じゃあ無理やりくっつければいいかというと、そうではありません。<br>
            ・「美味しい」と「美味い」を別々のIDにすると、共通する概念が失われます。<br>
            ・効率と理解のしやすさはトレードオフの関係にあります。
        </div>
    </div>

    <!-- Slide 4: PFN Solution -->
    <div class="slide">
        <div class="slide-header">
            <h2>3. PFNのアプローチ：形態素解析による調整</h2>
            <span class="page-num">03 / 14</span>
        </div>

        <div class="two-col">
            <div>
                <p>PFN (Plamo-2) は、「LLMにとって都合の良い分割」を経験則に基づいて定義した。</p>
                <div class="quote-box">
                    <p>形態素解析を使うことで、英語・日本語共にトークン効率とLLMの理解しやすさを調整している</p>
                </div>
            </div>
            <div>
                <h3>人間によるバランス調整</h3>
                <ul style="font-size:1.3rem;">
                    <li><strong>複合語 (新車):</strong> [新] + [車] に分割。<br>
                    → 他の語彙と意味を共有させる。</li>
                    <li><strong>単一語 (キャベツ):</strong> [キャベツ] で1つ。<br>
                    → 分割しても意味がないものは圧縮。</li>
                </ul>
            </div>
        </div>

        <p style="margin-top: 2rem; font-weight: bold; text-align: center; color: var(--secondary-color);">
            「形態素解析」をアンカーにすることで、<br>過度な圧縮を防ぎつつ効率を高めることに成功。
        </p>

        <div class="speaker-notes">
            <strong>【PFNの解: 2分】</strong><br>
            ・PFNはこの問題を「形態素解析」で解決しました。<br>
            ・人間が理解できる「意味の単位」で区切ることで、モデルにとっても理解しやすく、かつ効率的な分割を実現しています。
        </div>
    </div>

    <!-- Slide 5: Challenges of Existing Approach -->
    <div class="slide">
        <div class="slide-header">
            <h2>4. 既存アプローチに残る「3つの壁」</h2>
            <span class="page-num">04 / 14</span>
        </div>
        
        <p>形態素解析ベースの手法には、運用・拡張における重大な課題がある。</p>

        <div class="vocab-card">
            <h4 style="color:#b91c1c;">① 未知語・新語への対応コスト</h4>
            <p>「きゅんです」「ぴえん」のような新語が出るたびに辞書メンテが必要。<br>辞書にない言葉は意図しない分割になり、性能劣化の原因になる。</p>
        </div>

        <div class="vocab-card">
            <h4 style="color:#b91c1c;">② パフォーマンスコスト</h4>
            <p>大規模コーパスから語彙を収集する際、全テキストに対して形態素解析を実行する必要があり、前処理時間が膨大になる。</p>
        </div>

        <div class="vocab-card">
            <h4 style="color:#b91c1c;">③ 多言語展開の壁</h4>
            <p>言語ごとに最適な解析エンジン（MeCab, Sudachi, SentencePiece等）を選定・チューニングする必要があり、スケーラビリティがない。</p>
        </div>

        <div class="speaker-notes">
            <strong>【課題提起: 2分】</strong><br>
            ・しかし、この手法には運用上の壁があります。<br>
            ・新語への対応、計算コスト、そして何より「言語ごとにエンジンを用意する」という手間です。<br>
            ・世界中の言語に対応しようとした時、これでは破綻します。
        </div>
    </div>

    <!-- Slide 6: Meta BLT Deep Dive -->
    <div class="slide">
        <div class="slide-header">
            <h2>5. 別の道：Meta BLTの試みと課題</h2>
            <span class="page-num">05 / 14</span>
        </div>

        <h3>Meta BLT (Byte Latent Transformer)</h3>
        <p>トークナイザーを廃止し、バイト列を直接パッチ化して処理する手法。</p>

        <div class="two-col" style="margin-top:1.5rem;">
            <div style="background:white; padding:1.5rem; border-radius:8px;">
                <h4 style="margin-top:0;">BLTのアプローチ</h4>
                <p>文字をバイト(0-255)で扱い、固定長のパッチにまとめてエンコード。</p>
            </div>
            <div style="background:#fff1f2; padding:1.5rem; border-radius:8px;">
                <h4 style="margin-top:0; color:#991b1b;">BLTの不都合な真実</h4>
                <ul>
                    <li><strong>ASCIIバイアス:</strong> 1バイト文字(英語)に有利。</li>
                    <li><strong>固定パッチサイズ (Hyperparameter):</strong><br>
                        「何文字を1パッチにするか」を人間が決める必要がある。<br>
                        <span class="highlight">英語なら4文字、日本語なら2文字が最適...といった言語差に対応できない。</span></li>
                </ul>
            </div>
        </div>
        
        <p style="margin-top: 1.5rem; text-align:center;">
            多言語対応において、「固定長」で区切ることは本質的な解決にならない。
        </p>

        <div class="speaker-notes">
            <strong>【BLTの深掘り: 2分】</strong><br>
            ・MetaのBLTも有力な候補ですが、ここにも罠があります。<br>
            ・特に「パッチサイズ」の問題です。「何文字まとめるか」を人間が決める必要があります。<br>
            ・英語と日本語では情報の密度が違うため、固定長で切るとどちらかが犠牲になります。
        </div>
    </div>

    <!-- Slide 7: CLT Architecture (NEW) -->
    <div class="slide">
        <div class="slide-header">
            <h2>6. CLTの全体アーキテクチャ</h2>
            <span class="page-num">06 / 14</span>
        </div>
        
        <p>これらの課題を解決するために考案したのが、<br>
        <strong>Character Latent Transformer (CLT)</strong> です。</p>

        <div class="clt-pipeline">
            <div class="pipeline-box">
                <h4>1. Input</h4>
                <p>Raw Text</p>
                <div style="font-size:0.8rem;">(Unicode)</div>
            </div>
            <div class="arrow">→</div>
            <div class="pipeline-box">
                <h4>2. Decompose</h4>
                <p>High/Low Byte</p>
                <div style="font-size:0.8rem;">(Unicode分解)</div>
            </div>
            <div class="arrow">→</div>
            <div class="pipeline-box core">
                <h4>3. CIF</h4>
                <p>Encoder</p>
                <div style="font-size:0.8rem;">(動的圧縮)</div>
            </div>
            <div class="arrow">→</div>
            <div class="pipeline-box">
                <h4>4. Latent</h4>
                <p>Concepts</p>
                <div style="font-size:0.8rem;">(LLM入力)</div>
            </div>
        </div>

        <div class="two-col">
            <div>
                <h3>設計思想 (Core Concepts)</h3>
                <ul>
                    <li><strong>Unicode分解:</strong> バイトではなく文字ベースで公平化。</li>
                    <li><strong>CIF (動的圧縮):</strong> 固定長パッチを廃止し、情報密度で区切る。</li>
                    <li><strong>Latent Prior:</strong> 圧縮された「概念」をLLMが処理する。</li>
                </ul>
            </div>
            <div>
                <p>BLTの「パッチサイズ固定」問題を<br>
                CIFによる「動的区切り」で解決するアプローチです。</p>
            </div>
        </div>

        <div class="speaker-notes">
            <strong>【CLTアーキテクチャ説明: 2分】</strong><br>
            ・BLTの課題を受けて設計したのが、このCLTです。<br>
            ・まず入力をUnicodeで分解し、バイアスを消します。<br>
            ・次に、最も重要な「CIF」というモジュールを通します。<br>
            ・ここで動的に情報を圧縮し、「概念（Latent）」を作ってからLLMに渡す、というパイプラインになっています。
        </div>
    </div>

    <!-- Slide 8: CIF Detail -->
    <div class="slide">
        <div class="slide-header">
            <h2>7. 技術詳細：動的な区切り (CIF)</h2>
            <span class="page-num">07 / 14</span>
        </div>
        
        <p>CLTの核となる技術、<strong>Continuous Integrate-and-Fire (CIF)</strong> の仕組み。</p>

        <div class="cif-diagram">
            <div class="cif-step">
                <span>Input: "a"</span>
                <div class="cif-bucket"><div class="water" style="height: 20%"></div></div>
                <span style="font-size: 0.8rem;">Weight: 0.2</span>
            </div>
            <div class="arrow">+</div>
            <div class="cif-step">
                <span>Input: "nt"</span>
                <div class="cif-bucket"><div class="water" style="height: 100%; background: #ef4444;"></div></div>
                <span style="font-size: 0.8rem; color: #ef4444; font-weight:bold;">FIRE!</span>
            </div>
            <div class="arrow">→</div>
            <div class="cif-step">
                <span style="border: 2px solid #ef4444; padding: 5px; border-radius: 4px;">Token: "ant"</span>
            </div>
        </div>

        <div class="two-col">
            <div>
                <h3>動作原理</h3>
                <ul>
                    <li>情報量（予測の難しさ）をバケツに溜めていく。</li>
                    <li>閾値を超えたら「発火」して区切る。</li>
                </ul>
            </div>
            <div>
                <h3>メリット</h3>
                <ul>
                    <li><strong>ハイパーパラメータ不要:</strong> 言語ごとの最適な長さを人間が決める必要がない。</li>
                    <li><strong>完全なデータ駆動:</strong> 英語でも日本語でも、その言語の情報密度に合わせて勝手に区切る。</li>
                </ul>
            </div>
        </div>

        <div class="speaker-notes">
            <strong>【CIFの解説: 2分】</strong><br>
            ・CIFは「コップに水を溜める」ようなものです。<br>
            ・文字を読んでいって、「まだ意味が続くな」と思ったら水を溜める。<br>
            ・予測困難な箇所（意味の切れ目）で水が溢れ、そこで区切ります。<br>
            ・これにより、固定長ではなく、情報の密度に応じた「人間らしい」区切りが可能になります。
        </div>
    </div>

    <!-- Slide 9: Experiment Results (Fail) -->
    <div class="slide">
        <div class="slide-header">
            <h2>8. 検証結果：フルCLTの限界</h2>
            <span class="page-num">08 / 14</span>
        </div>
        
        <h3>検証したフルアーキテクチャ</h3>
        <div class="arch-diagram">
            [CLT Encoder] → <span style="color:#ef4444; font-weight:bold;">[Prior Layer]</span> → [LLM] → [CLT Decoder]
        </div>
        
        <div class="two-col" style="margin-top: 2rem;">
            <div>
                <h3 style="color: #10b981;">✅ 意図通りの動作</h3>
                <ul>
                    <li>CIFは機能し、可変長の「概念(Prior)」が生成された。</li>
                    <li>生の文字ではなく「概念」のみを使って学習・推論を実施。</li>
                </ul>
            </div>
            <div>
                <h3 style="color: #ef4444;">❌ 致命的なコスト</h3>
                <ul>
                    <li><strong>Next Token Prediction が難解:</strong><br>
                        「概念」の境界が動的に変わるため、Prior Model (次トークン予測) の学習が極めて不安定。</li>
                    <li>収束に莫大な計算資源が必要で実用的ではない。</li>
                </ul>
            </div>
        </div>
        <div class="speaker-notes">
            <strong>【失敗談: 1分】</strong><br>
            ・理想的なアーキテクチャを組んでみましたが、学習コストの壁にぶつかりました。<br>
            ・「動的に変わる区切り」を予測し続けるのは、LLMにとって荷が重すぎました。
        </div>
    </div>

    <!-- Slide 10: The Pivot -->
    <div class="slide">
        <div class="slide-header">
            <h2>9. 発想の転換 (The Pivot)</h2>
            <span class="page-num">09 / 14</span>
        </div>
        <div style="text-align: center; margin-top: 2rem;">
            <p style="font-size: 2rem; color: #ef4444; text-decoration: line-through;">
                Prior Modelによる「概念生成」を行う
            </p>
            <div style="font-size: 3rem; margin: 0.5rem 0;">⬇</div>
            <p style="font-size: 2.2rem; font-weight: bold; color: var(--primary-color);">
                Encoderによる「区切り(Segmentation)」のみを利用する
            </p>
        </div>

        <div style="background: white; padding: 2rem; border-radius: 8px; margin-top: 1rem; box-shadow: 0 4px 6px rgba(0,0,0,0.05);">
            <h3>新しい仮説</h3>
            <p>CLT Encoderは「予測しやすさ」に基づいて区切っているはず。<br>
            → <strong>その区切り結果を集めれば、PFNが求めていた「理想的な語彙」になるのでは？</strong></p>
        </div>

        <div class="speaker-notes">
            <strong>【ピボット: 1分】</strong><br>
            ・ここで発想を転換しました。「生成」はやめて、「区切り方」だけを拝借しようと。<br>
            ・Encoderがエントロピーに基づいて切った結果は、人間が苦労して形態素解析で作っていたものと同じになるはずだ、という仮説です。
        </div>
    </div>

    <!-- Slide 11: Neural Vocab Analysis -->
    <div class="slide">
        <div class="slide-header">
            <h2>10. 発見：Neural Vocab の品質</h2>
            <span class="page-num">10 / 14</span>
        </div>
        
        <div class="two-col">
            <div class="vocab-card">
                <h3>従来のBPEの傾向 (頻度ベース)</h3>
                <p>「たくさん出てくる形」をそのまま覚える</p>
                <div class="vocab-example"><span>starting</span> <span>(1 token)</span></div>
                <div class="vocab-example"><span>looked</span> <span>(1 token)</span></div>
            </div>
            <div class="vocab-card" style="border: 2px solid var(--accent-color);">
                <h3>CLTの傾向 (エントロピーベース)</h3>
                <p>「意味の最小単位」で切れている</p>
                <div class="vocab-example">
                    <span>start</span> + <span>ing</span>
                    <span class="highlight">← 接尾辞を分離</span>
                </div>
                <div class="vocab-example">
                    <span>look</span> + <span>ed</span>
                    <span class="highlight">← 過去形を分離</span>
                </div>
            </div>
        </div>
        
        <p style="margin-top: 2rem; text-align:center; font-weight:bold; font-size:1.6rem;">
            フィルタリング無しで、言語構造（Stem + Suffix）を自動発見。<br>
            PFNが目指した「意味のある分割」をデータのみで再現した。
        </p>

        <div class="speaker-notes">
            <strong>【結果の強調: 2分】</strong><br>
            ・結果はご覧の通りです。<br>
            ・CLTは教えられなくても、startとingを分けました。<br>
            ・これはPFNが「新車」を分けたかった意図と完全に一致します。<br>
            ・しかも、これを英語だけでなく全言語で自動的に行えるのです。
        </div>
    </div>

    <!-- Slide 12: Implementation (Aho-Corasick) -->
    <div class="slide">
        <div class="slide-header">
            <h2>11. 実装：エイホーコラシック法</h2>
            <span class="page-num">11 / 14</span>
        </div>
        
        <p>抽出された「Neural Vocab」をどう使うか？</p>

        <div class="two-col">
            <div>
                <h3>× BPE (Byte Pair Encoding)</h3>
                <p>頻度による「再結合」を行ってしまうため、せっかくCLTが見つけた自然な区切り（例: ingの分離）を壊してしまう恐れがある。</p>
            </div>
            <div>
                <h3>○ エイホーコラシック法</h3>
                <p>生成された語彙を辞書として、トライ木を用いた<strong>最長一致</strong>を行う。</p>
                <div class="vocab-card" style="border-left: 5px solid var(--primary-color);">
                    <p><strong>メリット:</strong><br>
                    CLTの意図した「意味分割」を100%再現しつつ、高速なトークナイズが可能。</p>
                </div>
            </div>
        </div>

        <div class="speaker-notes">
            <strong>【実装詳細: 1分】</strong><br>
            ・語彙を作った後、それをどう使うかも重要です。<br>
            ・BPEで再学習させると元の木阿弥なので、エイホーコラシック法を使って、見つけた語彙をそのまま辞書として適用する実装にしました。
        </div>
    </div>

    <!-- Slide 13: Comparison Summary -->
    <div class="slide">
        <div class="slide-header">
            <h2>12. アプローチの比較まとめ</h2>
            <span class="page-num">12 / 14</span>
        </div>

        <table class="comparison-table">
            <thead>
                <tr>
                    <th>項目</th>
                    <th>PFN (Morphological)</th>
                    <th>CLT (Entropy/CIF)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>原理</strong></td>
                    <td>言語学的知識 (辞書)</td>
                    <td><strong>情報理論 (予測確率)</strong></td>
                </tr>
                <tr>
                    <td><strong>分割基準</strong></td>
                    <td>人間が定義した形態素</td>
                    <td><strong>データが示す情報密度</strong></td>
                </tr>
                <tr>
                    <td><strong>新語対応</strong></td>
                    <td>辞書更新が必要 (コスト大)</td>
                    <td><strong>データさえあれば自動対応</strong></td>
                </tr>
                <tr>
                    <td><strong>多言語対応</strong></td>
                    <td>言語ごとにエンジンが必要</td>
                    <td><strong>全言語共通アーキテクチャ</strong></td>
                </tr>
            </tbody>
        </table>

        <div class="quote-box" style="margin-top: 2rem; text-align:center;">
            「形態素解析フリー」による<br>
            開発者バイアスの排除と言語平等の実現
        </div>

        <div class="speaker-notes">
            <strong>【総括: 2分】</strong><br>
            ・最後に比較です。<br>
            ・PFNの手法は「正解」を持っていますが、コストが高い。<br>
            ・CLTの手法は「データ」に従います。低コストで、あらゆる言語に適用可能です。
        </div>
    </div>

    <!-- Slide 14: Conclusion -->
    <div class="slide">
        <div class="slide-header">
            <h2>13. 結論と今後の展望</h2>
            <span class="page-num">13 / 14</span>
        </div>
        <ul>
            <li><strong>結論:</strong>
                <ul>
                    <li>完全なEnd-to-End学習は断念したが、<strong>「語彙生成器」</strong>としてのCLTは極めて優秀。</li>
                    <li>形態素解析器を持たない言語でも、日本語/英語と同等の「意味のある分割」が可能に。</li>
                </ul>
            </li>
            <li><strong>今後の展望:</strong>
                <ul>
                    <li>大規模コーパスでの学習と、全言語対応Vocabの作成。</li>
                    <li>特にLow-resource languages（解析器未発達な言語）での性能検証。</li>
                    <li>「どの言語でも安定して使えるLLM」の基盤技術へ。</li>
                </ul>
            </li>
        </ul>
        <div class="speaker-notes">
            <strong>【結び: 1分】</strong><br>
            ・この技術を使えば、リソースの少ない言語でも高品質なLLMが作れるようになります。<br>
            ・真の多言語対応AIの実現に向け、研究を続けます。<br>
            ・ご清聴ありがとうございました。
        </div>
    </div>
    
    <!-- Title Slide End -->
    <div class="slide title-slide">
        <h1>Thank You</h1>
        <p>Q & A</p>
    </div>

</div>

<!-- Navigation Controls -->
<div class="progress-bar" id="progressBar"></div>
<div class="controls">
    <button class="btn" onclick="prevSlide()">← Prev</button>
    <button class="btn" onclick="nextSlide()">Next →</button>
</div>

<script>
    let currentSlide = 0;
    const slides = document.querySelectorAll('.slide');
    const progressBar = document.getElementById('progressBar');

    function showSlide(index) {
        if (index < 0) index = 0;
        if (index >= slides.length) index = slides.length - 1;

        currentSlide = index;

        slides.forEach((slide, i) => {
            slide.classList.remove('active');
            if (i === currentSlide) {
                slide.classList.add('active');
            }
        });

        const progress = ((currentSlide + 1) / slides.length) * 100;
        progressBar.style.width = progress + '%';
    }

    function nextSlide() {
        showSlide(currentSlide + 1);
    }

    function prevSlide() {
        showSlide(currentSlide - 1);
    }

    document.addEventListener('keydown', (e) => {
        if (e.key === 'ArrowRight' || e.key === 'Space') {
            nextSlide();
        } else if (e.key === 'ArrowLeft') {
            prevSlide();
        }
    });

    showSlide(0);
</script>

</body>
</html>